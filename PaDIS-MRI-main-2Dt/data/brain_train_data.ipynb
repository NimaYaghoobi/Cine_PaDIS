{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943cde62-472a-4ce5-9fc3-5caad6a167dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--max_volumes MAX_VOLUMES]\n",
      "                             [--num_slices NUM_SLICES] --h5_folder H5_FOLDER\n",
      "                             [--output_root OUTPUT_ROOT]\n",
      "                             [--random_seed RANDOM_SEED]\n",
      "                             [--noise_level {32dB,22dB,12dB}] [--nproc NPROC]\n",
      "                             [--acs_size ACS_SIZE]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --h5_folder\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sigpy as sp\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm_base\n",
    "\n",
    "# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "\n",
    "###################################\n",
    "BART_ROOT = \"/home/fph5ms/bart\"\n",
    "os.environ[\"BART_TOOLBOX\"] = BART_ROOT\n",
    "os.environ[\"TOOLBOX_PATH\"] = BART_ROOT\n",
    "os.environ[\"PATH\"] = BART_ROOT + \":\" + os.environ.get(\"PATH\", \"\")\n",
    "sys.path.insert(0, os.path.join(BART_ROOT, \"python\"))\n",
    "from dnnlib.util import configure_bart\n",
    "configure_bart(BART_ROOT)\n",
    "###################################\n",
    "\n",
    "# from dnnlib.util import configure_bart\n",
    "# configure_bart()\n",
    "\n",
    "from bart import bart\n",
    "print('000')\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from data_utils import forward_fs, normalization_const, tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Process MRI volumes for training set.\")\n",
    "\n",
    "parser.add_argument('--max_volumes', type=int, default=200, help='Maximum number of volumes to process')\n",
    "parser.add_argument('--num_slices', type=int, default=1, help='Number of slices per volume')\n",
    "parser.add_argument('--h5_folder', type=str, required=True, help='Path to input folder containing .h5 files')\n",
    "parser.add_argument('--output_root', type=str, default=\"/data/datasets/fastmri/\", help='Path to output folder to save results')\n",
    "parser.add_argument('--random_seed', type=int, default=42, help='Seed for consistent sampling')\n",
    "parser.add_argument('--noise_level', type=str, default=\"32dB\", choices=[\"32dB\", \"22dB\", \"12dB\"], help='Noise level to add')\n",
    "parser.add_argument('--nproc', type=int, default=30, help='Number of CPU cores to use')\n",
    "parser.add_argument('--acs_size', type=int, default=24, help='Number of ACS lines to use')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device           = sp.cpu_device\n",
    "n_proc           = args.nproc # number of cpu cores to use, when possible\n",
    "num_slices       = args.num_slices \n",
    "center_slice     = 2\n",
    "ACS_size         = args.acs_size\n",
    "imsize           = 384\n",
    "\n",
    "db = args.noise_level\n",
    "\n",
    "if db == \"32dB\":\n",
    "    noise_amp = np.sqrt(0)\n",
    "elif db == \"22dB\":\n",
    "    noise_amp = np.sqrt(10)\n",
    "elif db == \"12dB\":\n",
    "    noise_amp = np.sqrt(100)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported db level: {db}\")\n",
    "    \n",
    "h5_folder = args.h5_folder\n",
    "ksp_files = [os.path.join(h5_folder, f) for f in os.listdir(h5_folder) if f.endswith(\".h5\")]\n",
    "if not ksp_files:\n",
    "    raise FileNotFoundError(f\"No .h5 files found in {h5_folder}\")\n",
    "print(f\"Found {len(ksp_files)} .h5 files in {h5_folder}\")\n",
    "\n",
    "max_volumes = args.max_volumes if args.max_volumes < len(ksp_files) else len(ksp_files)\n",
    "total_iterations = max_volumes * num_slices\n",
    "\n",
    "all_possible = list(range(len(ksp_files) * num_slices))\n",
    "rng = np.random.default_rng(seed=args.random_seed)\n",
    "indexes = rng.choice(all_possible, size=total_iterations, replace=False).tolist()\n",
    "\n",
    "\n",
    "x_est_gt = torch.zeros(total_iterations, imsize, imsize, dtype=torch.complex64)\n",
    "x_est = torch.zeros(total_iterations, imsize, imsize, dtype=torch.complex64)\n",
    "u_images = torch.zeros(total_iterations, imsize, imsize, dtype=torch.complex64)\n",
    "norm_consts_99 = torch.zeros(total_iterations, dtype=torch.float32)\n",
    "noise_var_noisy = torch.zeros(total_iterations, dtype=torch.float32)\n",
    "\n",
    "# path = \"/data/datasets/fastmri/brain_train_d384_s200/\"\n",
    "path = args.output_root + f\"brain_train_d{imsize}_s{max_volumes*num_slices}\" + f\"/{db}\"\n",
    "if not os.path.exists(path + \"/ksp/\"):\n",
    "    os.makedirs(path + \"/ksp/\")\n",
    "    \n",
    "def task(i):\n",
    "    idx = indexes[i]\n",
    "    sample_idx = idx // num_slices\n",
    "    slice_idx  = center_slice + np.mod(idx, num_slices) - num_slices // 2\n",
    "\n",
    "    # Load MRI samples and maps\n",
    "    with h5py.File(ksp_files[sample_idx], 'r') as contents:\n",
    "        # Get k-space for specific slice\n",
    "        ksp = np.asarray(contents['kspace'][slice_idx]).transpose(1, 2, 0)\n",
    "        cimg = bart(1, 'fft -iu 3', ksp) # compare to `bart fft -iu 3 ksp cimg`\n",
    "        cimg = sp.resize(cimg, [396, cimg.shape[1], cimg.shape[2]])\n",
    "\n",
    "    noise = cimg[0:30,0:30]\n",
    "    noise_flat = np.reshape(noise, (-1, cimg.shape[2]))\n",
    "    \n",
    "    ##\n",
    "    print(f\"cimg shape: {cimg.shape}\")\n",
    "    print(f\"noise_flat shape: {noise_flat.shape}\")\n",
    "    ##\n",
    "    cimg_white = sp.resize(bart(1, 'whiten', cimg[:,:,None,:], noise_flat[:,None,None,:]).squeeze(), [imsize, imsize, cimg.shape[2]])\n",
    "    cimg_white_noisy = cimg_white + (noise_amp / np.sqrt(2))*(np.random.normal(size=cimg_white.shape) + 1j * np.random.normal(size=cimg_white.shape))\n",
    "    \n",
    "    ksp_white = bart(1, 'fft -u 3', cimg_white)\n",
    "    ksp_white_noisy = bart(1, 'fft -u 3', cimg_white_noisy)\n",
    "    s_maps_white = bart(1, 'ecalib -m 1 -c0', ksp_white[:,:,None,:]).squeeze()\n",
    "    s_maps_white_noisy = bart(1, 'ecalib -m 1 -c0', ksp_white_noisy[:,:,None,:]).squeeze()\n",
    "    \n",
    "    gt_img_white_cropped = bart(1, 'pics -S -i 30', ksp_white[:,:,None,:], s_maps_white[:,:,None,:])\n",
    "    gt_img_white_cropped_noisy = bart(1, 'pics -S -i 30', ksp_white_noisy[:,:,None,:], s_maps_white_noisy[:,:,None,:])\n",
    "\n",
    "    ksp_white = ksp_white.transpose(2, 0, 1)\n",
    "    ksp_white_noisy = ksp_white_noisy.transpose(2, 0, 1)\n",
    "    s_maps_white = s_maps_white.transpose(2, 0, 1)  \n",
    "    s_maps_white_noisy = s_maps_white_noisy.transpose(2, 0, 1)  \n",
    "    cimg_white = cimg_white.transpose(2, 0, 1)  \n",
    "    cimg_white_noisy = cimg_white_noisy.transpose(2, 0, 1)  \n",
    "\n",
    "    norm_const_99_white = normalization_const(s_maps_white, gt_img_white_cropped, ACS_size=ACS_size)\n",
    "    norm_const_99_white_noisy = normalization_const(s_maps_white_noisy, gt_img_white_cropped_noisy, ACS_size=ACS_size)\n",
    "    ksp_white = ksp_white / norm_const_99_white\n",
    "    ksp_white_noisy = ksp_white_noisy / norm_const_99_white_noisy\n",
    "    s_maps_white = bart(1, 'ecalib -m 1 -c0', ksp_white.transpose(1, 2, 0)[:,:,None,:]).squeeze().transpose(2, 0, 1)\n",
    "    s_maps_white_noisy = bart(1, 'ecalib -m 1 -c0', ksp_white_noisy.transpose(1, 2, 0)[:,:,None,:]).squeeze().transpose(2, 0, 1)\n",
    "\n",
    "    gt_img_white_cropped = bart(1, 'pics -S -i 30', ksp_white.transpose(1, 2, 0)[:,:,None,:], s_maps_white.transpose(1, 2, 0)[:,:,None,:])\n",
    "    gt_img_white_cropped_noisy=bart(1, 'pics -S -i 30',ksp_white_noisy.transpose(1,2,0)[:,:,None,:],s_maps_white_noisy.transpose(1,2,0)[:,:,None,:])\n",
    "\n",
    "    cimg_white = bart(1, 'fft -iu 3', ksp_white.transpose(1, 2, 0)).transpose(2, 0, 1) # compare to `bart fft -iu 3 ksp cimg`\n",
    "    cimg_white_noisy = bart(1, 'fft -iu 3', ksp_white_noisy.transpose(1, 2, 0)).transpose(2, 0, 1) # compare to `bart fft -iu 3 ksp cimg`\n",
    "    \n",
    "    var = np.var(cimg_white[:, 0:30, 0:30])\n",
    "    var_noisy = np.var(cimg_white_noisy[:, 0:30, 0:30])\n",
    "    \n",
    "    coil_imgs_with_maps_white_noisy = cimg_white_noisy * np.conj(s_maps_white_noisy)\n",
    "    u_white_noisy = np.sum(coil_imgs_with_maps_white_noisy, axis = -3)\n",
    "    u_cropped_white_noisy = u_white_noisy\n",
    "\n",
    "    print('\\n')\n",
    "    print('white SNR: ' + str(10*np.log10(1/var)))\n",
    "    print('white_noisy SNR: ' + str(10*np.log10(1/var_noisy)))\n",
    "    print('gt norm: ' + str(np.linalg.norm(gt_img_white_cropped_noisy)))\n",
    "    print('u norm: ' + str(np.linalg.norm(u_cropped_white_noisy)))\n",
    "    \n",
    "    return i, gt_img_white_cropped, gt_img_white_cropped_noisy, u_cropped_white_noisy, norm_const_99_white_noisy, var_noisy, ksp_white_noisy, s_maps_white_noisy\n",
    "\n",
    "with Pool(n_proc) as p:\n",
    "    for i, gt_img_white_cropped, gt_img_white_cropped_noisy, u_cropped_white_noisy, norm_const_99, var_noisy, ksp_white_noisy, s_maps_white_noisy in tqdm(p.imap(task, range(total_iterations))):\n",
    "        x_est_gt[i] = torch.tensor(gt_img_white_cropped, dtype=torch.complex64)\n",
    "        x_est[i] = torch.tensor(gt_img_white_cropped_noisy, dtype=torch.complex64)\n",
    "        u_images[i] = torch.tensor(u_cropped_white_noisy, dtype=torch.complex64)\n",
    "        norm_consts_99[i] = torch.tensor(norm_const_99, dtype=torch.float32)\n",
    "        noise_var_noisy[i] = torch.tensor(var_noisy, dtype=torch.float32)\n",
    "        ksp_white_noisy = torch.tensor(ksp_white_noisy, dtype=torch.complex64)\n",
    "        s_maps_white_noisy = torch.tensor(s_maps_white_noisy, dtype=torch.complex64)\n",
    "        \n",
    "        torch.save({\n",
    "            \"ksp_white_noisy\": ksp_white_noisy,\n",
    "            \"s_maps_white_noisy\": s_maps_white_noisy},\n",
    "            path + \"/ksp/\" + str(i) + \".pt\")\n",
    "        print('Step ' + str(i) + ' Done')\n",
    "\n",
    "torch.save({'x_est_gt': x_est_gt,\n",
    "            'x_est': x_est,\n",
    "            'u_images': u_images,\n",
    "            'norm_consts_99': norm_consts_99,\n",
    "            'noise_var_noisy': noise_var_noisy},\n",
    "            path + \"/noisy.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4262a94-36cb-4362-92b5-535861b73f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nima's Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
