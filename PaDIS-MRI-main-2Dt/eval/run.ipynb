{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3572c8b0-d7c5-4975-bf80-4bea398864a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 9\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdnnlib\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPSHyperEvaluator\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import dnnlib\n",
    "\n",
    "from evaluator import DPSHyperEvaluator\n",
    "from utils import post_eval_normalize\n",
    "\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"DPS/EDM/ADMM experiment runner\")\n",
    "\n",
    "    p.add_argument(\"--model_path\", type=str, help=\"Path to network-snapshot .pkl (required for padis/edm)\")\n",
    "    p.add_argument(\"--val_dir\", type=str, required=True, help=\"Validation directory with .pt samples\")\n",
    "    p.add_argument(\"--image_size\", type=int, default=384)\n",
    "    p.add_argument(\"--pad\", type=int, default=64)\n",
    "    p.add_argument(\"--psize\", type=int, default=64)\n",
    "    p.add_argument(\"--mask_select\", type=int, default=7)\n",
    "    p.add_argument(\"--val_count\", type=int, default=32)\n",
    "    p.add_argument(\"--seed\", type=int, default=123)\n",
    "\n",
    "    # algo selection\n",
    "    p.add_argument(\"--algo\", type=str, required=True, choices=[\"padis\", \"edm\", \"admm\"], help=\"Choose reconstruction algo: padis, edm, or admm\")\n",
    "\n",
    "    # hyperparams\n",
    "    p.add_argument(\"--zeta\", type=float, default=3.0, help=\"Chosen zeta value (required for padis/edm calls)\")\n",
    "    p.add_argument(\"--steps\", type=int, default=104, help=\"Number of steps (or ADMM iters)\")\n",
    "    p.add_argument(\"--save_dir\", type=str, required=True, help=\"Where to write outputs\")\n",
    "    p.add_argument(\"--gpus\", type=int, nargs=\"+\", default=None, help=\"GPU ids (e.g. --gpus 0 1)\")\n",
    "    p.add_argument(\"--report_every\", type=int, default=1)\n",
    "    p.add_argument(\"--lam\", type=float, default=1e-4, help=\"Lambda for TV regularization in ADMM\")\n",
    "\n",
    "    # uncertainty quantification\n",
    "    p.add_argument(\"--run_evaluate_uncertainty\", action=\"store_true\")\n",
    "    p.add_argument(\"--uncertainty_mask_list\", type=str, default=\"0,1,2,3,4,5,6,7,8,9\", help=\"Comma-separated seeds for uncertainty (interpreted as seeds for padis/edm, mask ids for admm)\")\n",
    "\n",
    "    # patch size sweep\n",
    "    p.add_argument(\"--run_sweep_patch_sizes\", action=\"store_true\")\n",
    "    p.add_argument(\"--patch_sizes\", type=str, default=\"96\", help=\"Comma-separated patch sizes\")\n",
    "\n",
    "    # hyperparam search\n",
    "    p.add_argument(\"--run_hparam_search\", action=\"store_true\")\n",
    "    p.add_argument(\"--zeta_min\", type=float, default=1.0)\n",
    "    p.add_argument(\"--zeta_max\", type=float, default=10.0)\n",
    "    p.add_argument(\"--grid_points\", type=int, default=5)\n",
    "    p.add_argument(\"--random_samples\", type=int, default=5)\n",
    "    p.add_argument(\"--subset_size\", type=int, default=3)\n",
    "\n",
    "    # evaluate\n",
    "    p.add_argument(\"--run_evaluate\", action=\"store_true\")\n",
    "\n",
    "    # mask sweep\n",
    "    p.add_argument(\"--run_sweep_masks\", action=\"store_true\")\n",
    "    p.add_argument(\"--mask_list\", type=str, default=\"2,4,6,8,10\", help=\"Comma-separated mask IDs (or seeds)\")\n",
    "\n",
    "    # unconditional samples\n",
    "    p.add_argument(\"--run_uncond\", action=\"store_true\")\n",
    "    p.add_argument(\"--uncond_model_paths\", type=str, default=\"\", help=\"Comma-separated .pkl paths for unconditional sampling\")\n",
    "    p.add_argument(\"--num_samples_per_model\", type=int, default=3)\n",
    "\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "def parse_list(csv_str, cast=int):\n",
    "    if csv_str is None or csv_str == \"\":\n",
    "        return []\n",
    "    return [cast(x.strip()) for x in csv_str.split(\",\") if x.strip() != \"\"]\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    model = None\n",
    "    if args.algo in (\"padis\", \"edm\"):\n",
    "        if not args.model_path:\n",
    "            raise ValueError(\"--model_path is required for algo padis/edm\")\n",
    "        print(f'Loading network from \"{args.model_path}\"...')\n",
    "        with dnnlib.util.open_url(args.model_path, verbose=False) as f:\n",
    "            model = pickle.load(f)['ema']\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "    opt = DPSHyperEvaluator(\n",
    "        model=model,\n",
    "        mask_select=args.mask_select,\n",
    "        val_dir=args.val_dir,\n",
    "        image_size=args.image_size,\n",
    "        pad=args.pad,\n",
    "        psize=args.psize,\n",
    "        val_count=args.val_count,\n",
    "        seed=args.seed\n",
    "    )\n",
    "\n",
    "    tag = (\"whole\" if args.algo == \"edm\" else \"patch\") if args.algo != \"admm\" else \"admm\"\n",
    "\n",
    "    if args.run_hparam_search:\n",
    "        best_zeta = opt.hyperparam_search(\n",
    "            zeta_min=args.zeta_min,\n",
    "            zeta_max=args.zeta_max,\n",
    "            grid_points=args.grid_points,\n",
    "            random_samples=args.random_samples,\n",
    "            default_steps=args.steps,\n",
    "            subset_size=args.subset_size,\n",
    "        )\n",
    "        print(f\"[HParam] Best zeta is {best_zeta:.3f}\")\n",
    "        if args.zeta is None:\n",
    "            args.zeta = float(best_zeta)\n",
    "\n",
    "    if args.algo in (\"padis\", \"edm\") and args.zeta is None:\n",
    "        raise ValueError(\"--zeta is required for padis/edm runs (or run --run_hparam_search)\")\n",
    "\n",
    "    if args.run_evaluate_uncertainty:\n",
    "        mask_list = parse_list(args.uncertainty_mask_list, cast=int)\n",
    "        opt.evaluate_uncertainty(\n",
    "            mask_list=mask_list,\n",
    "            zeta=args.zeta if args.algo in (\"padis\", \"edm\") else 0.0,\n",
    "            num_steps=args.steps,\n",
    "            pad=args.pad,\n",
    "            psize=args.psize,\n",
    "            algo=args.algo,\n",
    "            save_dir=os.path.join(args.save_dir, \"uncertainty_run\"),\n",
    "            gpus=args.gpus,\n",
    "            report_every=args.report_every,\n",
    "            tag=tag,\n",
    "            lam=args.lam\n",
    "        )\n",
    "\n",
    "    if args.run_sweep_patch_sizes:\n",
    "        patch_sizes = parse_list(args.patch_sizes, cast=int)\n",
    "        opt.sweep_patch_sizes(\n",
    "            num_trials=args.val_count,\n",
    "            patch_sizes=patch_sizes,\n",
    "            zeta=args.zeta if args.algo in (\"padis\", \"edm\") else 0.0,\n",
    "            num_steps=args.steps,\n",
    "            save_dir=os.path.join(args.save_dir, \"patch_sweep\"),\n",
    "            algo=args.algo,\n",
    "            gpus=args.gpus,\n",
    "            tag=\"patch_sweep\",\n",
    "            report_every=args.report_every,\n",
    "        )\n",
    "\n",
    "    if args.run_evaluate:\n",
    "        metrics = opt.evaluate(\n",
    "            zeta=args.zeta if args.algo in (\"padis\", \"edm\") else 0.0,\n",
    "            num_steps=args.steps,\n",
    "            pad=args.pad,\n",
    "            psize=args.psize,\n",
    "            algo=args.algo,\n",
    "            save_dir=os.path.join(args.save_dir, \"evaluate\"),\n",
    "            tag=tag,\n",
    "            gpus=args.gpus,\n",
    "            report_every=args.report_every,\n",
    "            lam=args.lam,\n",
    "        )\n",
    "        s = metrics['summary']\n",
    "        print(f\"PSNR:  {s['psnr_mean']:.2f} ± {s['psnr_std']:.2f}\")\n",
    "        print(f\"SSIM:  {s['ssim_mean']:.4f} ± {s['ssim_std']:.4f}\")\n",
    "        print(f\"NRMSE: {s['nrmse_mean']:.4f} ± {s['nrmse_std']:.4f}\")\n",
    "\n",
    "    if args.run_sweep_masks:\n",
    "        mask_list = parse_list(args.mask_list, cast=int)\n",
    "        opt.sweep_masks(\n",
    "            num_trials=args.val_count,\n",
    "            mask_list=mask_list,\n",
    "            zeta=args.zeta if args.algo in (\"padis\", \"edm\") else 0.0,\n",
    "            num_steps=args.steps,\n",
    "            save_dir=os.path.join(args.save_dir, \"mask_sweep\"),\n",
    "            algo=args.algo,\n",
    "            gpus=args.gpus,\n",
    "            tag=tag,\n",
    "            report_every=args.report_every,\n",
    "            lam=args.lam,\n",
    "        )\n",
    "\n",
    "    if args.run_uncond:\n",
    "        paths = [p for p in args.uncond_model_paths.split(\",\") if p.strip()]\n",
    "        if not paths:\n",
    "            raise ValueError(\"--run_uncond requires --uncond_model_paths with at least one .pkl path\")\n",
    "        opt.generate_unconditional_samples(\n",
    "            model_paths=paths,\n",
    "            output_root=os.path.join(args.save_dir, \"uncond\"),\n",
    "            num_samples_per_model=args.num_samples_per_model,\n",
    "            algo=args.algo,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "\n",
    "\n",
    "    # Compute final metrics and plots. \n",
    "    recon_dir = os.path.join(args.save_dir, \"evaluate\", \"recons\")\n",
    "    plot_dir = os.path.join(args.save_dir, \"evaluate\", \"comp_plots\")\n",
    "    try:\n",
    "        post_eval_normalize(\n",
    "            recon_dir=recon_dir,\n",
    "            val_dir=args.val_dir,\n",
    "            plot_dir=plot_dir,\n",
    "            json_basename=\"results\",\n",
    "            mask_select=args.mask_select,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[post_eval_normalize] Skipped due to error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b86373-2912-42dd-849d-c251f4d8600b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nima's Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
